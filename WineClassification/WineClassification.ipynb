{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from save_csv import results_to_csv\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import numpy.random as sample\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy.linalg as la\n",
    "from scipy.special import expit\n",
    "norm = la.norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collectinig Wine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_contents = sio.loadmat('data.mat')\n",
    "X = data_contents['X']\n",
    "ones = [[1] for _ in range(X.shape[0])]\n",
    "X = np.append(X,ones,1)\n",
    "y = np.array([val[0] for val in data_contents['y']])\n",
    "X_test = data_contents['X_test']\n",
    "y = np.array([[v] for v in y])\n",
    "X = np.append(X,y,1)\n",
    "np.random.shuffle(X)\n",
    "X,y = np.array([row[:-1] for row in X]),np.array([row[-1] for row in X])  \n",
    "X_train = X[:5000]\n",
    "y_train = y[:5000]\n",
    "X_val = X[5000:]\n",
    "y_val = y[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Gradient Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[0]\n",
    "d = X_train.shape[1]\n",
    "w = np.array([0]*d)\n",
    "e = 0.0000009\n",
    "lam = 0.05\n",
    "alpha = 0.000001\n",
    "s = np.array([expit(np.dot(X_train[i],w)) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(X,y,w,e,s):\n",
    "    w = w - e * (2*lam*w - np.matmul(X.T,y-s))\n",
    "    s = np.array([expit(np.dot(X[i],w)) for i in range(n)])\n",
    "    return w,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_update(X,w,e,s,y,i):\n",
    "    w = w - e * (2*lam*w - (y[i]-s[i])*X[i])\n",
    "    s = np.array([expit(np.dot(X[i],w)) for i in range(n)])\n",
    "    return w,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y,w,lam,s):\n",
    "    Sum = sum([y[i]*np.log(s[i]) + (1-y[i])*np.log(1-s[i]) for i in range(n)])\n",
    "    res = lam*np.dot(w,w) - Sum\n",
    "    print('Cost: ' + str(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(X,w,y):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(X)):\n",
    "        total += 1\n",
    "        a = np.dot(X[i],w)\n",
    "        s = expit(a)\n",
    "        p = 1 if s >= 0.5 else 0\n",
    "        if p == y[i]:\n",
    "            correct += 1\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs  = []\n",
    "# working parameters: alpha = 0.0001, e = 0.0000005, lam = 0.005\n",
    "prev_acc = float('inf')\n",
    "acc = 1\n",
    "strikes = 0\n",
    "# initialize\n",
    "max_acc = -float('inf')\n",
    "max_w = []\n",
    "w_prev = np.array([-2]*d)\n",
    "while strikes < 5000:\n",
    "    prev_acc = acc\n",
    "    costs.append(cost(y_train,w,lam,s))\n",
    "    w_prev = w\n",
    "    w,s = update(X_train,y_train,w_prev,e,s)\n",
    "    acc = compute_accuracy(X_val,w, y_val)\n",
    "    if acc < prev_acc:\n",
    "        strikes += 1\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        max_w = w\n",
    "    print(\"Accuracy: \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min Cost: \" + str(min(costs)))\n",
    "print(\"Max Accuracy: \" + str(max_acc))\n",
    "plt.figure()\n",
    "plt.title('costs vs iterations')\n",
    "plt.plot([i for i in range(len(costs))][10:], costs[10:],'r-',label='Gradient Descent Cost')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('cost')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[0]\n",
    "d = X_train.shape[1]\n",
    "w = np.array([0]*d)\n",
    "e = 0.00007\n",
    "lam = 0.05\n",
    "alpha = 0.00000001\n",
    "s = np.array([expit(np.dot(X_train[i],w)) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs  = [[],[],[],[]]\n",
    "\n",
    "prev_acc = float('inf')\n",
    "acc = 1\n",
    "strikes = 0\n",
    "max_acc = [-float('inf') for _ in range(4)]\n",
    "max_w = [[] for _ in range(4)]\n",
    "# initialize\n",
    "w_prev = np.array([-2]*d)\n",
    "i = 0\n",
    "for lam in [0.5,0.05,0.005,0.0005]:\n",
    "    print(\"-\"*10 + \"Lambda: \" + str(lam)+\"-\"*10)\n",
    "    prev_acc = float('inf')\n",
    "    j = 0\n",
    "    while strikes < 200:\n",
    "        costs[i].append(cost(y_train,w,lam,s))\n",
    "        w_prev = w\n",
    "        w,s = stochastic_update(X_train,w_prev,e,s,y_train,j)\n",
    "        acc = compute_accuracy(X_val,w, y_val)\n",
    "        if acc < prev_acc:\n",
    "            strikes += 1\n",
    "        if acc > max_acc[i]:\n",
    "            max_acc[i] = acc\n",
    "            max_w[i] = w\n",
    "        print(\"Accuracy: \" + str(acc))\n",
    "        j += 1\n",
    "        if j >= 5000:\n",
    "            j = 0\n",
    "        prev_acc = acc\n",
    "    i += 1\n",
    "    strikes = 0\n",
    "    w = np.array([0]*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(costs)):\n",
    "    print(\"Min Cost: \" + str((costs[i].index(min(costs[i])), min(costs[i]))))\n",
    "    print(\"lambda: \" + str(lam))\n",
    "    print(\"Max Accuracy: \" + str(max_acc[i]))\n",
    "    plt.figure()\n",
    "    plt.title('costs vs iterations')\n",
    "    plt.plot([i for i in range(len(costs[i]))], costs[i],'r-',label='Gradient Descent Cost')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('cost')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decreasing Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[0]\n",
    "d = X_train.shape[1]\n",
    "w = np.array([0]*d)\n",
    "e = 0.05\n",
    "lam = 0.5\n",
    "alpha = 0.00001\n",
    "s = np.array([expit(np.dot(X_train[i],w)) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs  = []\n",
    "\n",
    "# initialize\n",
    "i = 1\n",
    "e0 = e\n",
    "w_prev = np.array([-2]*d)\n",
    "j = 0\n",
    "max_acc = -float('inf')\n",
    "max_w = []\n",
    "prev_acc = float('inf')\n",
    "strikes = 0\n",
    "diff = float('inf')\n",
    "while diff > alpha:\n",
    "    costs.append(cost(y_train,w,lam,s))\n",
    "    w_prev = w\n",
    "    w,s = stochastic_update(X_train,w_prev,e0,s,y_train,j)\n",
    "    e0 = e / i\n",
    "    i += 1\n",
    "    j += 1\n",
    "    if j >= 5000:\n",
    "        j = 0\n",
    "    acc = compute_accuracy(X_val,w, y_val)\n",
    "    if acc < prev_acc:\n",
    "            strikes += 1\n",
    "    if acc < prev_acc:\n",
    "        strikes += 1\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        max_w = w\n",
    "    prev_acc = acc\n",
    "    diff = abs(norm(w)-norm(w_prev))\n",
    "    print(\"Accuracy: \" + str(acc))\n",
    "    print(\"Diff: \" + str(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Min Cost: \" + str((costs.index(min(costs)), min(costs))))\n",
    "print(\"Max Accuracy: \" + str(max_acc))\n",
    "# costs = [c for c in costs if c < 4000]\n",
    "plt.figure()\n",
    "plt.title('costs vs iterations')\n",
    "plt.plot([i for i in range(len(costs))], costs,'r-',label='Gradient Descent Cost')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('cost')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,w):\n",
    "    res = []\n",
    "    for i in range(len(X)):\n",
    "        a = np.dot(X[i],w)\n",
    "        s = expit(a)\n",
    "        p = 1 if s >= 0.5 else 0\n",
    "        res.append(p)\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
